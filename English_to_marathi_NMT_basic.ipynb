{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English to marathi NMT basic",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "22dauBZeQiSO"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW8PpJ8HQsuN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlbtUSoRQzW0"
      },
      "source": [
        "lines = open('mar.txt', encoding='utf-8').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBvZNwPRQzZz",
        "outputId": "9e76ab14-3687-4cf5-d776-54ee5c96152e"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/mar-eng.zip\n",
        "!!unzip mar-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  mar-eng.zip',\n",
              " '  inflating: mar.txt                 ',\n",
              " '  inflating: _about.txt              ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3Xn_6MQzc6"
      },
      "source": [
        "lines = open('mar.txt', encoding='utf-8').read().split('\\n')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siUroKZWQzfN"
      },
      "source": [
        "eng_sent = []\n",
        "mar_sent = []\n",
        "eng_chars = set()\n",
        "mar_chars = set()\n",
        "nb_samples = 10000\n",
        "\n",
        "# Process english and french sentences\n",
        "for line in range(nb_samples):\n",
        "    \n",
        "    eng_line = str(lines[line]).split('\\t')[0]\n",
        "    \n",
        "    # Append '\\t' for start of the sentence and '\\n' to signify end of the sentence\n",
        "    mar_line = '\\t' + str(lines[line]).split('\\t')[1] + '\\n'\n",
        "    eng_sent.append(eng_line)\n",
        "    mar_sent.append(mar_line)\n",
        "    \n",
        "    for ch in eng_line:\n",
        "        if (ch not in eng_chars):\n",
        "            eng_chars.add(ch)\n",
        "            \n",
        "    for ch in mar_line:\n",
        "        if (ch not in mar_chars):\n",
        "            mar_chars.add(ch)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyxT48PaQzhm"
      },
      "source": [
        "\n",
        "mar_chars = sorted(list(mar_chars))\n",
        "eng_chars = sorted(list(eng_chars))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGZkwwGpQzkf"
      },
      "source": [
        "# dictionary to index each english character - key is index and value is english character\n",
        "eng_index_to_char_dict = {}\n",
        "\n",
        "# dictionary to get english character given its index - key is english character and value is index\n",
        "eng_char_to_index_dict = {}\n",
        "\n",
        "for k, v in enumerate(eng_chars):\n",
        "    eng_index_to_char_dict[k] = v\n",
        "    eng_char_to_index_dict[v] = k"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYdJ-C_JREuG"
      },
      "source": [
        "# dictionary to index each french character - key is index and value is french character\n",
        "mar_index_to_char_dict = {}\n",
        "\n",
        "# dictionary to get french character given its index - key is french character and value is index\n",
        "mar_char_to_index_dict = {}\n",
        "for k, v in enumerate(mar_chars):\n",
        "    mar_index_to_char_dict[k] = v\n",
        "    mar_char_to_index_dict[v] = k"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRohWU7pREyB"
      },
      "source": [
        "max_len_eng_sent = max([len(line) for line in eng_sent])\n",
        "max_len_mar_sent = max([len(line) for line in mar_sent])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnNc519YRbVE",
        "outputId": "28d0b05c-34a7-42c6-9aae-c2de3249b60a"
      },
      "source": [
        "\n",
        "max_len_eng_sent\n",
        "max_len_mar_sent"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwVY3pHBRbX_"
      },
      "source": [
        "tokenized_eng_sentences = np.zeros(shape = (nb_samples,max_len_eng_sent,len(eng_chars)), dtype='float32')\n",
        "tokenized_mar_sentences = np.zeros(shape = (nb_samples,max_len_mar_sent,len(mar_chars)), dtype='float32')\n",
        "target_data = np.zeros((nb_samples, max_len_mar_sent, len(mar_chars)),dtype='float32')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KEWKxEVRbbE"
      },
      "source": [
        "for i in range(nb_samples):\n",
        "    for k,ch in enumerate(eng_sent[i]):\n",
        "        tokenized_eng_sentences[i,k,eng_char_to_index_dict[ch]] = 1\n",
        "        \n",
        "    for k,ch in enumerate(mar_sent[i]):\n",
        "        tokenized_mar_sentences[i,k,mar_char_to_index_dict[ch]] = 1\n",
        "\n",
        "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "        if k > 0:\n",
        "            target_data[i,k-1,mar_char_to_index_dict[ch]] = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFO979DFRbdk"
      },
      "source": [
        "encoder_input = Input(shape=(None,len(eng_chars)))\n",
        "encoder_LSTM = LSTM(256,return_state = True)\n",
        "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
        "encoder_states = [encoder_h, encoder_c]\n",
        "\n",
        "# from keras.layers import Input, LSTM, Embedding, Dense\n",
        "# latent_dim = 50\n",
        "# # Encoder\n",
        "# encoder_inputs = Input(shape=(None,))\n",
        "# enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "# encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "# encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# # We discard `encoder_outputs` and only keep the states.\n",
        "# encoder_states = [state_h, state_c]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnw5HyuyRbfl"
      },
      "source": [
        "\n",
        "decoder_input = Input(shape=(None,len(mar_chars)))\n",
        "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
        "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
        "decoder_dense = Dense(len(mar_chars),activation='softmax')\n",
        "decoder_out = decoder_dense (decoder_out)\n",
        "\n",
        "\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLe4pzWPRnJ-"
      },
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.fit(x=[tokenized_eng_sentences,tokenized_mar_sentences], \n",
        "          y=target_data,\n",
        "          batch_size=64,\n",
        "          epochs=50,\n",
        "          validation_split=0.1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV-vfkYeRnNG"
      },
      "source": [
        "# Inference models for testing\n",
        "\n",
        "# Encoder inference model\n",
        "encoder_model_inf = Model(encoder_input, encoder_states)\n",
        "\n",
        "# Decoder inference model\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
        "                                                 initial_state=decoder_input_states)\n",
        "\n",
        "decoder_states = [decoder_h , decoder_c]\n",
        "\n",
        "decoder_out = decoder_dense(decoder_out)\n",
        "\n",
        "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
        "                          outputs=[decoder_out] + decoder_states )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p3KvySSRnPt"
      },
      "source": [
        "def decode_seq(inp_seq):\n",
        "    \n",
        "    # Initial states value is coming from the encoder \n",
        "    states_val = encoder_model_inf.predict(inp_seq)\n",
        "    \n",
        "    target_seq = np.zeros((1, 1, len(mar_chars)))\n",
        "    target_seq[0, 0, mar_char_to_index_dict['\\t']] = 1\n",
        "    \n",
        "    translated_sent = ''\n",
        "    stop_condition = False\n",
        "    \n",
        "    while not stop_condition:\n",
        "        \n",
        "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
        "        \n",
        "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
        "        sampled_mar_char = mar_index_to_char_dict[max_val_index]\n",
        "        translated_sent += sampled_mar_char\n",
        "        \n",
        "        if ( (sampled_mar_char == '\\n') or (len(translated_sent) > max_len_mar_sent)) :\n",
        "            stop_condition = True\n",
        "        \n",
        "        target_seq = np.zeros((1, 1, len(mar_chars)))\n",
        "        target_seq[0, 0, max_val_index] = 1\n",
        "        \n",
        "        states_val = [decoder_h, decoder_c]\n",
        "        \n",
        "    return translated_sent"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7j4Qc74SzlK",
        "outputId": "b2dca65b-2604-49c4-be23-77871bedd5f6"
      },
      "source": [
        "for seq_index in range(50):\n",
        "    inp_seq = tokenized_eng_sentences[seq_index:seq_index+1]\n",
        "    translated_sent = decode_seq(inp_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', eng_sent[seq_index])\n",
        "    print('Decoded sentence:', translated_sent)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: ऊ.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: को.\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: पा.\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: वा.\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: वा.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: उडी मार.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: उडी मार.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: उडी मार.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: उडी मार.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: थां.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: थां.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: वा.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: वा.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: सांग.\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: लवकर.\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: लवकर.\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: लवकर.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: मी पिरलं.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: मी पिरलं.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: ऊ.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: कालं.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: कसलं.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: कसलं.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: कसलं.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: कसलं.\n",
            "\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: तो पातला.\n",
            "\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: तो पातला.\n",
            "\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: तो पातला.\n",
            "\n",
            "-\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: तो पातला.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: मी पडला.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: मी पडला.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: मी पडला.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: मी पडला.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: माहीत आहे.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: माहीत आहे.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: माहीत आहे.\n",
            "\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: मी होला.\n",
            "\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: मी होला.\n",
            "\n",
            "-\n",
            "Input sentence: I spit.\n",
            "Decoded sentence: मी होला.\n",
            "\n",
            "-\n",
            "Input sentence: I spit.\n",
            "Decoded sentence: मी होला.\n",
            "\n",
            "-\n",
            "Input sentence: I work.\n",
            "Decoded sentence: मी काम करतो.\n",
            "\n",
            "-\n",
            "Input sentence: I work.\n",
            "Decoded sentence: मी काम करतो.\n",
            "\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: मी जां आहे.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: ऊ.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBmwZ1CpSzob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx6CrnJDSzq5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}